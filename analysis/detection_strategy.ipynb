{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5e80f3bc",
   "metadata": {},
   "source": [
    "# Finding a detection strategy\n",
    "It is necesary to obtain the bounding box of the faces present for every frame on all videos. The GPU-backed face detector allows to efficiently process many frames in parallel. Despite this, running the face detector for all frames adds up to a considerable time. Addtionally, the face detector is agnostic to previous results leading to undesirable gaps and jittering. A gap is a short secuence of frames where the face remains undetected before suddenly returning, while jittering presents itself when succesive high-frequency detections result in bounding box coordinates that sharply oscillate.\n",
    "\n",
    "Lowering the number of frames run trough the face detector the total time for the operation can be atenuated. The factor for wich the detection is sped-up is given by the ratio between the video length and the time spent processing it. The video dimesions are also a factor to consider, as a bigger frame will implies more time transfering data between memories. To find the speedup factor a random sample of 150 videos was selected and the face detector run with a frame rate of 30, 15, 6, and 3 FPS. As per default configuration, all videos were resized by a factor of 8. A second run capped the resolution to a maximum of *NUM x NUM*, keeping the aspect ratio.\n",
    "\n",
    "> 30FPS was used as a base reference for it being the maximum frame rate posible with the acquired videos. 1000 Random samples of 5 seconds were extracted from the 3846 tracks.\n",
    "\n",
    "> The high-frequency error can be filtered by running a smoothing operation. This takes the form of a moving window averaging past detections. A stable detection sequence can be improved by adjusting the contribution of the elements by their relative distance to the sampled item. Several weighting strategies were tried and the one with the lowest MSE was chosen. The smoothed 30FPS sequence is the closest to an ideal result and it will be used as a reference for further experiments.\n",
    "\n",
    "> This introduces periodical and regular gaps on the sequence of bounding boxes. Applying an extrapolation strategy can fill any existing gaps. Additionally lowering the frequency of detections can mitigate jittering by smoothing the transition between detected points. Several interpolation estrategies can be tried. Implementation of spline interpolators of zeroth, first, second and third order are already available on the *Python* library *SciPy*.\n",
    "\n",
    "> Weights with uniform contribution, linearly decreasing and gaussian distributed were compared.\n",
    "\n",
    "> A sample of 150 randomly selected files were used to find a usefull strategy.\n",
    "\n",
    "> Sampling rates of 15, 6, and 3 FPS were compared against a gaussian-smoothed .\n",
    "\n",
    "> ## Compensating for the jittering\n",
    "> 30FPS is too high-frequency, it introduces jittering.\n",
    "\n",
    "> Jittering is an undesired problem on the high-frequency 30FPS tracked boxes used as reference samples. Applying a moving window averaging the previous elements acts as a low-pass filter reducing the jitter. Three weighting strategies were used: uniform, lineal and gaussian.\n",
    "\n",
    "> + Uniform estrategy averages the last n elements with equal weights.\n",
    "> + Linear strategy weights the elements by the time-distance to the current sample, normalized by the longest.\n",
    "> + Gaussian strategy weights by the gaussian value on the time-axis, centered on the current sample with a standard deviation of the detection period.\n",
    "\n",
    "> + Does lowering the frame rate make an improovement on detection time?\n",
    "    + By how much?\n",
    "    + Thresholding the frame size to a maximum value may help too, what dimensions to use as threshold?\n",
    "> + Averaging past detections decrease the jittering?\n",
    "    + Which performs the best?\n",
    "> + Which interpolation strategy is closer to the true detection?\n",
    "    + Which is closer to the softened detection?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7f221c94",
   "metadata": {},
   "outputs": [],
   "source": [
    "VIDEO_LENGTH_FILE = r'../data/video_length.csv'\n",
    "TRACK_LENGTH_FILE = r'../data/track_length.csv'\n",
    "TRACK_POINTS_FILE = r'../data/video_points.pkl'\n",
    "TRACK_FOLDERS = {\n",
    "    30: r'../data/test_tracks@30FPS',\n",
    "    15: r'../data/test_tracks@15FPS',\n",
    "    6: r'../data/test_tracks@6FPS',\n",
    "    3: r'../data/test_tracks@3FPS',\n",
    "}\n",
    "REFERENCE_FRAME_RATE = 30\n",
    "SAMPLE_LENGTH = 5.0\n",
    "SAMPLE_NUM = 5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f6ea7452",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import json\n",
    "import pickle\n",
    "from datetime import timedelta\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Patch\n",
    "from scipy.interpolate import interp1d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7f9c28a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_length_data(track_folders):\n",
    "    video_data = []\n",
    "    track_data = []\n",
    "    \n",
    "    for fps, path in track_folders.items():\n",
    "        for track_file in Path(path).glob('**/*.tracks.json'):\n",
    "            with track_file.open('r', encoding='utf8') as fp:\n",
    "                track_file = json.load(fp)\n",
    "            \n",
    "            # Video lengths\n",
    "            video_data.append([track_file['video_duration'],\n",
    "                               track_file['detection_duration'],\n",
    "                               track_file['width'],\n",
    "                               track_file['height'],\n",
    "                               fps])\n",
    "\n",
    "            # Track lengths\n",
    "            for track in track_file['tracks'].values():\n",
    "                track_data.append([track['time'][-1] - track['time'][0],\n",
    "                                   track_file['width'],\n",
    "                                   track_file['height'],\n",
    "                                   fps])\n",
    "    return video_data, track_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1d3a648d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_point_data(track_folder):\n",
    "    data_time = []\n",
    "    data_bbox = []\n",
    "    data_kpts = []\n",
    "    data_tlen = []\n",
    "\n",
    "    for track_file in Path(track_folder).glob('**/*.tracks.json'):\n",
    "        with track_file.open('r', encoding='utf8') as fp:\n",
    "            track_file = json.load(fp)\n",
    "\n",
    "        # Ignore videos without tracks\n",
    "        if len(track_file['tracks']) == 0:\n",
    "            continue\n",
    "\n",
    "        track_time, track_bbox, track_kpts = zip(*[(t['time'], t['bbox'], t['kpts']) for t in track_file['tracks'].values()])\n",
    "\n",
    "        track_time = list(track_time)\n",
    "        track_bbox = list(track_bbox)\n",
    "        track_kpts = list(track_kpts)\n",
    "        track_tlen = []\n",
    "\n",
    "        for i, (t, b, k) in enumerate(zip(track_time, track_bbox, track_kpts)):        \n",
    "            # All tracks start from 0\n",
    "            t = np.float32(t) - t[0]\n",
    "            track_time[i] = t.tolist()\n",
    "\n",
    "            # Length of a track in seconds\n",
    "            track_tlen.append(t[-1])\n",
    "\n",
    "            # Box positions from screen center\n",
    "            b = np.float32(b).reshape(-1, 2, 2)\n",
    "            b[:, :, 0] -= 0.5 * track_file['width']\n",
    "            b[:, :, 1] -= 0.5 * track_file['height']\n",
    "            track_bbox[i] = b.tolist()\n",
    "\n",
    "            # Point positions from screen center\n",
    "            k = np.float32(k).reshape(-1, 5, 2)\n",
    "            k[:, :, 0] -= 0.5 * track_file['width']\n",
    "            k[:, :, 1] -= 0.5 * track_file['height']\n",
    "            track_kpts[i] = k.tolist()\n",
    "\n",
    "        data_time.extend(track_time)\n",
    "        data_bbox.extend(track_bbox)\n",
    "        data_kpts.extend(track_kpts)\n",
    "        data_tlen.extend(track_tlen)\n",
    "    return data_time, data_bbox, data_kpts, data_tlen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69c25b55",
   "metadata": {},
   "outputs": [],
   "source": [
    "video_data_src = Path(VIDEO_LENGTH_FILE)\n",
    "track_data_src = Path(TRACK_LENGTH_FILE)\n",
    "point_data_src = Path(TRACK_POINTS_FILE)\n",
    "\n",
    "video_data_columns = [('video_length', float),\n",
    "                      ('time_detecting', float),\n",
    "                      ('width', int),\n",
    "                      ('height', int),\n",
    "                      ('fps', int)]\n",
    "track_data_columns = [('track_length', float),\n",
    "                      ('width', int),\n",
    "                      ('height', int),\n",
    "                      ('fps', int)]\n",
    "\n",
    "# Load video data\n",
    "if video_data_src.exists() and track_data_src.exists:\n",
    "    video_df = pd.read_csv(video_data_src, index_col=0, dtype=dict(video_data_columns))\n",
    "    track_df = pd.read_csv(track_data_src, index_col=0, dtype=dict(track_data_columns))\n",
    "else:\n",
    "    video_data, track_data = load_length_data(TRACK_FOLDERS)\n",
    "    \n",
    "    video_df = pd.DataFrame.from_records(video_data, columns=[n for n, t in video_data_columns])\n",
    "    track_df = pd.DataFrame.from_records(track_data, columns=[n for n, t in track_data_columns])\n",
    "    \n",
    "    video_df.to_csv(video_data_src)\n",
    "    track_df.to_csv(track_data_src)\n",
    "\n",
    "# Load track data\n",
    "if point_data_src.exists():\n",
    "    with point_data_src.open('rb') as fp:\n",
    "        data_time, data_bbox, data_kpts, data_tlen = pickle.load(fp)\n",
    "else:\n",
    "    data_time, data_bbox, data_kpts, data_tlen = load_point_data(TRACK_FOLDERS[REFERENCE_FRAME_RATE])\n",
    "    \n",
    "    with point_data_src.open('wb') as fp:\n",
    "        pickle.dump((data_time, data_bbox, data_kpts, data_tlen), fp, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7b19df45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 3846 tracks\n"
     ]
    }
   ],
   "source": [
    "num_tracks = len(data_time)\n",
    "print('There are', num_tracks, 'tracks')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b1201e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sampling tracks\n",
    "np.random.seed(0)\n",
    "\n",
    "# Pick random track and a random position to start a slice\n",
    "track_samples = (np.random.random(SAMPLE_NUM) * len(data_time)).astype(int)\n",
    "track_start = np.random.random(SAMPLE_NUM) * (np.float32(data_tlen)[track_samples] - SAMPLE_LENGTH)\n",
    "\n",
    "test_time = []\n",
    "test_bbox = []\n",
    "test_kpts = []\n",
    "\n",
    "for ti, ts in zip(track_samples, track_start):\n",
    "    t_time = []\n",
    "    t_bbox = []\n",
    "    t_kpts = []\n",
    "    # Add the frames that lie between the picked slice bounds\n",
    "    for i in range(len(data_time[ti])):\n",
    "        if ts <= data_time[ti][i] < ts + SAMPLE_LENGTH:\n",
    "            t_time.append(data_time[ti][i])\n",
    "            t_bbox.append(data_bbox[ti][i])\n",
    "            t_kpts.append(data_kpts[ti][i])\n",
    "    # Make slices start from 0\n",
    "    test_time.append(np.float32(t_time) - t_time[0])\n",
    "    test_bbox.append(np.float32(t_bbox))\n",
    "    test_kpts.append(np.float32(t_kpts))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e3db8e5",
   "metadata": {},
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3006a167",
   "metadata": {},
   "outputs": [],
   "source": [
    "video_df['area'] = video_df['width'] * video_df['height']\n",
    "video_df['speedup'] = video_df['video_length'] / video_df['time_detecting']\n",
    "\n",
    "df = video_df.groupby(['area', 'fps']).agg([np.mean, np.std]).reset_index(level='area')\n",
    "\n",
    "fig = plt.figure(figsize=(10, 6))\n",
    "ax = plt.axes()\n",
    "markers='x*o^'\n",
    "\n",
    "for marker, (key, group) in zip(markers, df.groupby('fps')):\n",
    "    yerr = group[('speedup', 'std')].fillna(0)\n",
    "    ax.errorbar(group['area'], group[('speedup', 'mean')], yerr=yerr, fmt=marker, label=f'{key} FPS')\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.title('Speedup by Frame Rate')\n",
    "plt.xlabel('Area')\n",
    "plt.ylabel('Speedup')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2a6f330",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Track distribution by duration color by framerate\n",
    "fig = plt.figure(figsize=(10, 6))\n",
    "ax = plt.axes()\n",
    "\n",
    "labels, track_lengths = zip(*[(f'{key} FPS', group['track_length']) for key, group in track_df.groupby('fps')])\n",
    "ax.hist(track_lengths, bins=20, label=labels, range=(0, 3600))\n",
    "ax.set_yscale('log')\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.title('Track distribution by length')\n",
    "plt.xlabel('Track length in seconds')\n",
    "plt.ylabel('Number of tracks')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0f31c4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaussian(x, mu, sigma):\n",
    "    return (1.0 / np.sqrt(2 * np.pi * sigma**2)) * np.exp(-((x - mu)**2) / (2 * sigma**2))\n",
    "\n",
    "def soften(x, y, win_size, fn):\n",
    "    soft_y = []\n",
    "    for c in range(len(x)):\n",
    "        istart = max(c - win_size, 0)\n",
    "        iend = c + 1\n",
    "        # iend = min(c + win_size, len(x)-1)\n",
    "        weights = fn(x[istart:iend])\n",
    "        weights = weights / np.sum(weights)\n",
    "        soft_y.append(np.average(y[istart:iend], weights=weights, axis=0))\n",
    "    return np.float32(soft_y)\n",
    "\n",
    "def mse(x0, x1, axis=None):\n",
    "    return np.mean((x0 - x1)**2)\n",
    "\n",
    "def get_center_area(bbox):\n",
    "    cter = np.sqrt(np.sum((0.5 * np.sum(bbox, axis=1))**2, axis=-1))\n",
    "    area = (bbox[:, 1, 0] - bbox[:, 0, 0]) * (bbox[:, 1, 1] - bbox[:, 0, 1])\n",
    "    cter = cter - np.mean(cter)\n",
    "    area = area - np.mean(area)\n",
    "    return cter, area\n",
    "\n",
    "def get_error(ldiff):\n",
    "    udiff = -ldiff\n",
    "    ldiff[ldiff < 0] = 0\n",
    "    udiff[udiff < 0] = 0\n",
    "    return (ldiff, udiff)\n",
    "\n",
    "def select_times(in_times, in_period, out_period):\n",
    "    out_times = np.round(in_times / in_period).astype(int)\n",
    "    k = int(np.round(out_period / in_period))\n",
    "    out_times = np.mod(out_times, k)\n",
    "    return np.argwhere(out_times == 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92062e2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_cases = { \n",
    "    'Uniform': lambda x: np.ones_like(x),\n",
    "    'Linear': lambda x: 1.0 / (np.abs(x - x[-1]) + 1.0),\n",
    "    'Gaussian': lambda x: gaussian(x, x[-1], 1.0 / REFERENCE_FRAME_RATE),\n",
    "}\n",
    "\n",
    "softened_bbox = {k: [] for k in test_cases}\n",
    "cat_test_bbox = np.concatenate(test_bbox)\n",
    "for label, op in test_cases.items():\n",
    "    for true_time, true_bbox in zip(test_time, test_bbox):    \n",
    "        soft_bbox = soften(true_time, true_bbox, 5, op)\n",
    "        softened_bbox[label].append(soft_bbox)\n",
    "    print(label, 'MSE:', mse(cat_test_bbox, np.concatenate(softened_bbox[label])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcc4c857",
   "metadata": {},
   "outputs": [],
   "source": [
    "err = []\n",
    "for true_time, true_bbox in zip(test_time, test_bbox):    \n",
    "    soft_bbox = soften(true_time, true_bbox, 5, test_cases['Gaussian'])\n",
    "    err.append(mse(true_bbox, soft_bbox))\n",
    "# err = np.stack(err)\n",
    "print('Min index:', np.argmin(err))\n",
    "print('Max index:', np.argmax(err))\n",
    "print('Median index:', np.argsort(err)[len(err)//2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b777a245",
   "metadata": {},
   "outputs": [],
   "source": [
    "NROWS, NCOLS = 1, 2\n",
    "EXAMPLE_IDX = 985\n",
    "\n",
    "true_time = test_time[EXAMPLE_IDX]\n",
    "true_bbox = test_bbox[EXAMPLE_IDX]\n",
    "    \n",
    "fig, axs = plt.subplots(nrows=NROWS, ncols=NCOLS, figsize=(8*NCOLS, 8*NROWS),\n",
    "                        constrained_layout=True, squeeze=False)\n",
    "cter_ax = axs[0, 0]\n",
    "area_ax = axs[0, 1]\n",
    "\n",
    "true_cter, true_area = get_center_area(true_bbox)\n",
    "cter_ax.scatter(true_time, true_cter, marker='o', label='Data')\n",
    "area_ax.scatter(true_time, true_area, marker='o', label='Data')\n",
    "\n",
    "# Plot softened data with the displacement from True with an error bar\n",
    "for (label, op), m in zip(test_cases.items(), 'x*+'):\n",
    "    soft_bbox = soften(true_time, true_bbox, 5, op)\n",
    "    soft_cter, soft_area = get_center_area(soft_bbox)\n",
    "    \n",
    "    mse_err = mse(test_bbox[EXAMPLE_IDX], softened_bbox[label][EXAMPLE_IDX])\n",
    "    print(label, mse_err)\n",
    "    \n",
    "    cter_ax.scatter(true_time, soft_cter, marker=m, label=label + f' $MSE={mse_err}$')\n",
    "    area_ax.scatter(true_time, soft_area, marker=m, label=label + f' $MSE={mse_err}$')\n",
    "    \n",
    "cter_ax.set_title('Center')\n",
    "cter_ax.legend()\n",
    "area_ax.set_title('Area')\n",
    "area_ax.legend()\n",
    "\n",
    "fig.suptitle('Softening', fontsize=16)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3d3117a",
   "metadata": {},
   "outputs": [],
   "source": [
    "interpolation_kinds = ['zero', 'slinear', 'quadratic', 'cubic']\n",
    "frame_rates = [15, 6, 3]\n",
    "soft_type = ['', '+Gauss']\n",
    "\n",
    "op = lambda x: gaussian(x, x[-1], 1.0 / REFERENCE_FRAME_RATE)\n",
    "reference_soft_bbox = [soften(time, bbox, 5, op) for time, bbox in zip(test_time, test_bbox)]\n",
    "cat_reference_soft_bbox = np.concatenate(reference_soft_bbox)\n",
    "\n",
    "mse_results = {}\n",
    "mse_soft_results = {}\n",
    "transformed_bbox = {}\n",
    "table = []\n",
    "for fr in frame_rates:\n",
    "    for kind in interpolation_kinds:\n",
    "        for is_soft in soft_type:\n",
    "            label = f'{kind}{is_soft}@{fr}FPS'\n",
    "            transformed_bbox[label] = transformed_bbox.get(label, [])\n",
    "            \n",
    "            for true_time, true_bbox in zip(test_time, test_bbox):\n",
    "                idx = select_times(true_time, 1.0 / REFERENCE_FRAME_RATE, 1.0 / fr)\n",
    "                time = true_time[idx].flatten()\n",
    "                bbox = true_bbox[idx].reshape(-1, 2, 2)\n",
    "                \n",
    "                if len(is_soft) != 0:\n",
    "                    bbox = soften(time, bbox, 5, op)\n",
    "                try:\n",
    "                    bbox_inter = interp1d(time, bbox, kind=kind, bounds_error=False, fill_value='extrapolate', axis=0)\n",
    "                    y = bbox_inter(true_time)\n",
    "                except ValueError as e:\n",
    "                    y = np.zeros_like(true_bbox)\n",
    "                transformed_bbox[label].append(y)\n",
    "            \n",
    "            mse_true = mse(cat_test_bbox, np.concatenate(transformed_bbox[label]))\n",
    "            mse_soft = mse(cat_reference_soft_bbox, np.concatenate(transformed_bbox[label]))\n",
    "            \n",
    "            mse_results[label] = mse_true\n",
    "            mse_soft_results[label] = mse_soft\n",
    "            table.append([kind, len(is_soft) != 0, fr, mse_true, mse_soft])\n",
    "            # print(label, 'MSE:', mse_true, 'Soft MSE:', mse_soft)\n",
    "\n",
    "df = pd.DataFrame(table, columns=['interpolation_type', 'gaussian_softening', 'frame_rate', 'MSE', 'MSE_soft'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bdc533d",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9379d55",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "width = 0.75\n",
    "hatch_pattern = '\\\\'\n",
    "\n",
    "def plot_fig(results, interpolation_kinds, use_log, title):\n",
    "    fig = plt.figure(figsize=(12, 6))\n",
    "    ax = plt.axes()\n",
    "\n",
    "    positions = np.stack([np.linspace(i - width / 2, i + width/2, len(soft_type) * len(interpolation_kinds))\n",
    "                          for i in np.arange(len(frame_rates))])\n",
    "    positions = positions.reshape(len(frame_rates), len(interpolation_kinds), len(soft_type))\n",
    "\n",
    "    for i, kind in enumerate(interpolation_kinds):\n",
    "        values = []\n",
    "        for fr in frame_rates:\n",
    "            values.extend([results[f'{kind}{is_soft}@{fr}FPS'] for is_soft in soft_type])\n",
    "        b = ax.bar(positions[:, i].flatten(), values, width / (len(soft_type) * len(interpolation_kinds)), label=kind)\n",
    "        for k, bb in enumerate(b):\n",
    "            if k % 2 == 1:\n",
    "                bb.set_hatch(hatch_pattern)\n",
    "    if use_log:\n",
    "        ax.set_yscale('log')\n",
    "    fig.tight_layout()\n",
    "    plt.xticks(np.arange(len(frame_rates)), [f'{fr} FPS' for fr in frame_rates])\n",
    "    handles, labels = ax.get_legend_handles_labels()\n",
    "    handles.append(Patch(facecolor='w', hatch=hatch_pattern, label='Gaussian Softening'))\n",
    "    plt.legend(handles=handles)\n",
    "    plt.title(title)\n",
    "    plt.show()\n",
    "\n",
    "plot_fig(mse_results, ['zero', 'slinear', 'quadratic', 'cubic'], True, 'MSE against Detections')\n",
    "plot_fig(mse_results, ['zero', 'slinear'], False, 'MSE against Detections')\n",
    "plot_fig(mse_soft_results, ['zero', 'slinear', 'quadratic', 'cubic'], True, 'MSE against Softented Detections')\n",
    "plot_fig(mse_soft_results, ['zero', 'slinear'], False, 'MSE against Softented Detections')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02d6fbcb",
   "metadata": {},
   "source": [
    "# Apendix: Gauss Smoothing example\n",
    "On the previous figure, the vertical lines are equally distance by the time between frames, or period $P$. For the third previous element, its contribution is close to zero.\n",
    "\n",
    "Thus the weight of element $j$ with respect to element $i$ is:\n",
    "$\n",
    "W(t_j, t_i)=\n",
    "\\begin{cases}\n",
    "    \\frac{1}{P \\sqrt{2 \\pi}} e^{-\\frac{1}{2}(\\frac{t_j-t_i}{P})^2} & \\forall j <= i\\\\\n",
    "    0 & \\text{otherwise}.\n",
    "\\end{cases}\n",
    "$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87a14056",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax = plt.axes()\n",
    "\n",
    "# Plot vertical lines\n",
    "for x in np.arange(0, 1, (1.0 / 30.0)):\n",
    "    if x == 0.5:\n",
    "        color = 'red'\n",
    "    else:\n",
    "        color = '#0f0f0f50'\n",
    "    plt.axvline(x=x, color=color)\n",
    "\n",
    "# Plot gaussian distribution\n",
    "x = np.arange(0, 1, 1.0 / 300.0)\n",
    "for i in range(1, 5):\n",
    "    y = gaussian(x, 0.5, i / 30.0)\n",
    "    y = y / np.sum(y)\n",
    "    ax.plot(x, y, label=f'$\\sigma={i} \\\\times P$')\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
